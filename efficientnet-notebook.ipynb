{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","execution_count":null,"source":["#Importing Essential Libraries and Modules\r\n","\r\n","import torch\r\n","import torch.nn as nn\r\n","import torch.optim as optim\r\n","import numpy as np\r\n","import torchvision\r\n","from torchvision import datasets, models, transforms\r\n","import matplotlib.pyplot as plt\r\n","import time\r\n","import os\r\n","import copy\r\n","from torch.utils.tensorboard import SummaryWriter\r\n","import timm\r\n","from torchvision.transforms import CenterCrop"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["torch.manual_seed(0)\r\n","\r\n","\r\n","class MaxCenterCrop:\r\n","    def __call__(self, sample):\r\n","        min_size = min(sample.size[0], sample.size[1])\r\n","        return CenterCrop(min_size)(sample)\r\n"],"outputs":[],"metadata":{"trusted":true}},{"cell_type":"code","execution_count":null,"source":["#Setting up the batch size and device to GPU \r\n","\r\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\r\n","batch_size = 16\r\n","\r\n"],"outputs":[],"metadata":{"trusted":true}},{"cell_type":"code","execution_count":null,"source":["#Creating data loaders for training  and validation.\r\n","\r\n","data_dir = 'data'\r\n","train_dir = data_dir + '/train'\r\n","valid_dir = data_dir + '/val'\r\n","\r\n","data_transforms_train = transforms.Compose([MaxCenterCrop(),\r\n","                                            transforms.Resize(256),\r\n","                                            transforms.ToTensor()])\r\n","\r\n","data_transforms_validation = transforms.Compose([MaxCenterCrop(),\r\n","                                            transforms.Resize(256),\r\n","                                            transforms.ToTensor()])\r\n","\r\n","image_dataset_train = datasets.ImageFolder(train_dir, transform = data_transforms_train)\r\n","\r\n","image_dataset_validation = datasets.ImageFolder(valid_dir, transform = data_transforms_validation)\r\n","\r\n","\r\n","dataloader_train = torch.utils.data.DataLoader(image_dataset_train, batch_size=batch_size,\r\n","                                                shuffle=True)\r\n","\r\n","dataloader_valid = torch.utils.data.DataLoader(image_dataset_validation, batch_size=batch_size,\r\n","                                                shuffle=True)\r\n","\r\n"],"outputs":[],"metadata":{"trusted":true}},{"cell_type":"code","execution_count":null,"source":["#Uploading the efficientnet_b7 pretrained model and modification\r\n","\r\n","\r\n","class_names = image_dataset_train.classes\r\n","\r\n","model = timm.create_model('efficientnet_b7', pretrained=True)\r\n","\r\n","num_ftrs = model.classifier.in_features\r\n","\r\n","model.classifier = nn.Linear(num_ftrs, len(class_names))\r\n","\r\n","model = model.to(device)\r\n"],"outputs":[],"metadata":{"trusted":true}},{"cell_type":"code","execution_count":null,"source":["#Setting up the optimizer and the criterion\r\n","\r\n","optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\r\n","criterion = nn.CrossEntropyLoss()\r\n","\r\n"],"outputs":[],"metadata":{"trusted":true}},{"cell_type":"code","execution_count":null,"source":["from ignite.engine import Engine, _prepare_batch, create_supervised_trainer\r\n","\r\n","\r\n","trainer = create_supervised_trainer(model, optimizer, criterion, device)"],"outputs":[],"metadata":{"trusted":true}},{"cell_type":"code","execution_count":null,"source":["#Metrics\r\n","\r\n","from ignite.metrics import Loss, TopKCategoricalAccuracy, Precision, Recall\r\n","\r\n","\r\n","metrics = {\r\n","    'loss': Loss(criterion),\r\n","    'TopKCategoricalAccuracy1': TopKCategoricalAccuracy(k=1),\r\n","    'TopKCategoricalAccuracy5': TopKCategoricalAccuracy(k=5),\r\n","    'avg_precision': Precision(average=True), \r\n","    'avg_recall': Recall(average=True)\r\n","}\r\n","\r\n"],"outputs":[],"metadata":{"trusted":true}},{"cell_type":"code","execution_count":null,"source":["#Progress bar\r\n","\r\n","from ignite.contrib.handlers.tqdm_logger import ProgressBar\r\n","\r\n","pbar = ProgressBar(bar_format='')\r\n","pbar.attach(trainer, output_transform=lambda x: {'loss': x})\r\n","\r\n"],"outputs":[],"metadata":{"trusted":true}},{"cell_type":"code","execution_count":null,"source":["#Defining evaluators\r\n","\r\n","from ignite.engine import create_supervised_evaluator\r\n","\r\n","train_evaluator = create_supervised_evaluator(model, metrics=metrics, device=device)\r\n","val_evaluator = create_supervised_evaluator(model, metrics=metrics, device=device)\r\n","\r\n"],"outputs":[],"metadata":{"trusted":true}},{"cell_type":"code","execution_count":null,"source":["from torch.utils.data.dataset import Subset\r\n","\r\n","random_indices = np.random.permutation(np.arange(len(image_dataset_train)))[:len(image_dataset_validation)]\r\n","\r\n","train_subset = Subset(image_dataset_train, indices=random_indices)\r\n","\r\n","train_eval_loader = torch.utils.data.DataLoader(train_subset, batch_size=batch_size, shuffle=True, \r\n","                               drop_last=True, pin_memory=\"cuda\")"],"outputs":[],"metadata":{"trusted":true}},{"cell_type":"code","execution_count":null,"source":["#Metrics computation\r\n","\r\n","from ignite.engine import Events\r\n","\r\n","@trainer.on(Events.EPOCH_COMPLETED)\r\n","def compute_and_display_offline_train_metrics(engine):\r\n","    epoch = engine.state.epoch\r\n","    print(\"Compute train metrics...\")\r\n","    metrics = train_evaluator.run(train_eval_loader).metrics\r\n","    print(\"Training Results - Epoch: {}  Loss: {:.4f} | TopKCategoricalAccuracy1: {:.4f} | Precision: {:.4f} | Recall: {:.4f}\"\r\n","          .format(engine.state.epoch, metrics['loss'], metrics['TopKCategoricalAccuracy1'], metrics['avg_precision'], metrics['avg_recall']))\r\n","    \r\n","    \r\n","@trainer.on(Events.EPOCH_COMPLETED)\r\n","def compute_and_display_val_metrics(engine):\r\n","    epoch = engine.state.epoch\r\n","    print(\"Compute validation metrics...\")\r\n","    metrics = val_evaluator.run(dataloader_valid).metrics\r\n","    print(\"Validation Results - Epoch: {}  Loss: {:.4f} | TopKCategoricalAccuracy1: {:.4f} | Precision: {:.4f} | Recall: {:.4f}\"\r\n","          .format(engine.state.epoch, metrics['loss'], metrics['TopKCategoricalAccuracy1'], metrics['avg_precision'], metrics['avg_recall']))  \r\n","\r\n"],"outputs":[],"metadata":{"trusted":true}},{"cell_type":"code","execution_count":null,"source":["#Run training\r\n","\r\n","\r\n","Start_one = time.time()\r\n","\r\n","max_epochs = 3\r\n","\r\n","output = trainer.run(dataloader_train, max_epochs=max_epochs)\r\n","\r\n","End_one = Start_one - time.time()\r\n","\r\n","print('Training complete in {:.0f}m {:.0f}s'.format(End_one // 60, End_one % 60))"],"outputs":[],"metadata":{"trusted":true}}]}